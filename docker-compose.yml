version: '3.8'

services:
  # Production service configuration
  stable-diffusion-api:
    build: 
      context: .
      target: application
    container_name: stable-diffusion-api-prod
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Model Configuration
      - MODEL_CACHE_DIR=/app/models
      - MODEL_NAME=${MODEL_NAME:-runwayml/stable-diffusion-v1-5}
      
      # Performance Configuration
      - MAX_CONCURRENT_REQUESTS=${MAX_CONCURRENT_REQUESTS:-1}
      - GENERATION_TIMEOUT=${GENERATION_TIMEOUT:-60}
      - ENABLE_ATTENTION_SLICING=${ENABLE_ATTENTION_SLICING:-true}
      - ENABLE_CPU_OFFLOAD=${ENABLE_CPU_OFFLOAD:-true}
      
      # API Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_TITLE=Stable Diffusion API
      - API_VERSION=1.0.0
      
      # Security Configuration
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-*}
    volumes:
      # Model cache persistence
      - stable_diffusion_models:/app/models
      # Log persistence
      - stable_diffusion_logs:/app/logs
      # Configuration
      - ./.env:/app/.env:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: ${MEMORY_LIMIT:-8G}
          cpus: '${CPU_LIMIT:-4.0}'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 120s
    networks:
      - stable_diffusion_network
    profiles:
      - production

  # Development service configuration
  stable-diffusion-api-dev:
    build: 
      context: .
      target: application
    container_name: stable-diffusion-api-dev
    ports:
      - "${DEV_API_PORT:-8001}:8000"
    environment:
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Model Configuration
      - MODEL_CACHE_DIR=/app/models
      - MODEL_NAME=${MODEL_NAME:-runwayml/stable-diffusion-v1-5}
      
      # Performance Configuration (relaxed for development)
      - MAX_CONCURRENT_REQUESTS=1
      - GENERATION_TIMEOUT=120
      - ENABLE_ATTENTION_SLICING=true
      - ENABLE_CPU_OFFLOAD=true
      
      # API Configuration (debug mode)
      - LOG_LEVEL=DEBUG
      - API_TITLE=Stable Diffusion API (Development)
      - API_VERSION=1.0.0-dev
      
      # Development specific
      - PYTHONPATH=/app
      - RELOAD=true
    volumes:
      # Live code reloading
      - .:/app
      # Model cache persistence
      - stable_diffusion_models:/app/models
      # Log persistence
      - stable_diffusion_logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
          cpus: '4.0'
    restart: unless-stopped
    command: ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload", "--log-level", "debug"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 60s
    networks:
      - stable_diffusion_network
    profiles:
      - development

  # Optional: Reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: stable-diffusion-nginx
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - stable-diffusion-api
    restart: unless-stopped
    networks:
      - stable_diffusion_network
    profiles:
      - production
      - nginx

# Named volumes for data persistence
volumes:
  stable_diffusion_models:
    driver: local
  stable_diffusion_logs:
    driver: local

# Custom network for service communication
networks:
  stable_diffusion_network:
    driver: bridge